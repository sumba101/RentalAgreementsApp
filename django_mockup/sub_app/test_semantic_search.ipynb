{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a516e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from texttable import Texttable\n",
    "\n",
    "from dataset_handler import *\n",
    "from semantic_search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416378df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join('data', 'dataset')\n",
    "indices_dir = os.path.join('data', 'indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815d04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(query_embeddings, index):\n",
    "    neighbors = index.knnQueryBatch(query_embeddings, k=1, num_threads=2)\n",
    "    output_ids = [neighbor[0][0] + 1 for neighbor in neighbors]\n",
    "    match_scores = [neighbor[1][0] for neighbor in neighbors]\n",
    "    \n",
    "    return output_ids, match_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808a42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(true_ids, output_ids):\n",
    "    n = len(true_ids)\n",
    "    acc = np.sum(np.array(true_ids) == np.array(output_ids)) / n\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4926f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clause_ids, output_ids, match_scores):\n",
    "    table = Texttable()\n",
    "    table.add_row(['clause_id', 'output_id', 'match_score'])\n",
    "    table.add_rows(list(zip(clause_ids, output_ids, match_scores)), header=False)\n",
    "    print(table.draw())\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9698901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clause_id</th>\n",
       "      <th>query</th>\n",
       "      <th>clause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>Remove any major changes to house before leaving.</td>\n",
       "      <td>The tenant shall at the termination of this ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>Take license if you're carrying out business.</td>\n",
       "      <td>The tenant shall himself obtain the license fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "      <td>Make sure you're having a license if doing som...</td>\n",
       "      <td>The tenant shall himself obtain the license fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>I won't provide any insurance or security cover.</td>\n",
       "      <td>All kinds of security arrangements insurances ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>Stay good with neighbors.</td>\n",
       "      <td>The tenant shall keep good relationship with n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  clause_id                                              query  \\\n",
       "0  100          1  Remove any major changes to house before leaving.   \n",
       "1  200          2      Take license if you're carrying out business.   \n",
       "2  201          2  Make sure you're having a license if doing som...   \n",
       "3  300          3   I won't provide any insurance or security cover.   \n",
       "4  400          4                          Stay good with neighbors.   \n",
       "\n",
       "                                              clause  \n",
       "0  The tenant shall at the termination of this ag...  \n",
       "1  The tenant shall himself obtain the license fo...  \n",
       "2  The tenant shall himself obtain the license fo...  \n",
       "3  All kinds of security arrangements insurances ...  \n",
       "4  The tenant shall keep good relationship with n...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clauses_dict, query_clauses = load_dataset(dataset_dir=dataset_dir)\n",
    "print(query_clauses.shape)\n",
    "query_clauses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539511db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 49)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = query_clauses['query'].tolist()\n",
    "clause_ids = query_clauses['clause_id'].tolist()\n",
    "len(queries), len(clause_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956a1141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clauses = load_clauses(dataset_dir=dataset_dir)\n",
    "len(clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff02fb7",
   "metadata": {},
   "source": [
    "## For SRoBERTa-NLI-STSb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9439f819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PreTrainedTokenizerFast(name_or_path='sentence-transformers/roberta-base-nli-stsb-mean-tokens', vocab_size=50262, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}),\n",
       " RobertaModel(\n",
       "   (embeddings): RobertaEmbeddings(\n",
       "     (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "     (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "     (token_type_embeddings): Embedding(1, 768)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (encoder): RobertaEncoder(\n",
       "     (layer): ModuleList(\n",
       "       (0): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (2): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (3): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (4): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (5): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (6): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (7): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (8): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (9): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (10): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (11): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pooler): RobertaPooler(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (activation): Tanh()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer, model = load_models()\n",
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb4162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clause_embeddings = get_embeddings(clauses, tokenizer, model)\n",
    "clause_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1adc9512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nmslib.FloatIndex method='hnsw' space='cosinesimil' at 0x5640a0cc01f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_and_store_index(clause_embeddings, name=os.path.join(indices_dir, 'roberta_base_nli_stsb'))\n",
    "index = load_index(name=os.path.join(indices_dir, 'roberta_base_nli_stsb'))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee8feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = get_embeddings(queries, tokenizer, model)\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b63bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+\n",
      "| clause_id | output_id | match_score |\n",
      "+-----------+-----------+-------------+\n",
      "| 1         | 44        | 0.397       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 2         | 0.365       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 2         | 0.423       |\n",
      "+-----------+-----------+-------------+\n",
      "| 3         | 12        | 0.474       |\n",
      "+-----------+-----------+-------------+\n",
      "| 4         | 4         | 0.100       |\n",
      "+-----------+-----------+-------------+\n",
      "| 5         | 5         | 0.272       |\n",
      "+-----------+-----------+-------------+\n",
      "| 6         | 6         | 0.268       |\n",
      "+-----------+-----------+-------------+\n",
      "| 7         | 36        | 0.253       |\n",
      "+-----------+-----------+-------------+\n",
      "| 8         | 8         | 0.478       |\n",
      "+-----------+-----------+-------------+\n",
      "| 9         | 9         | 0.325       |\n",
      "+-----------+-----------+-------------+\n",
      "| 10        | 10        | 0.184       |\n",
      "+-----------+-----------+-------------+\n",
      "| 11        | 11        | 0.167       |\n",
      "+-----------+-----------+-------------+\n",
      "| 12        | 16        | 0.447       |\n",
      "+-----------+-----------+-------------+\n",
      "| 13        | 13        | 0.415       |\n",
      "+-----------+-----------+-------------+\n",
      "| 14        | 14        | 0.558       |\n",
      "+-----------+-----------+-------------+\n",
      "| 15        | 15        | 0.449       |\n",
      "+-----------+-----------+-------------+\n",
      "| 16        | 16        | 0.491       |\n",
      "+-----------+-----------+-------------+\n",
      "| 17        | 12        | 0.405       |\n",
      "+-----------+-----------+-------------+\n",
      "| 18        | 18        | 0.305       |\n",
      "+-----------+-----------+-------------+\n",
      "| 19        | 19        | 0.439       |\n",
      "+-----------+-----------+-------------+\n",
      "| 20        | 20        | 0.593       |\n",
      "+-----------+-----------+-------------+\n",
      "| 21        | 38        | 0.325       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.262       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.288       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.384       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 38        | 0.366       |\n",
      "+-----------+-----------+-------------+\n",
      "| 23        | 23        | 0.380       |\n",
      "+-----------+-----------+-------------+\n",
      "| 24        | 24        | 0.423       |\n",
      "+-----------+-----------+-------------+\n",
      "| 25        | 36        | 0.303       |\n",
      "+-----------+-----------+-------------+\n",
      "| 26        | 26        | 0.281       |\n",
      "+-----------+-----------+-------------+\n",
      "| 27        | 27        | 0.353       |\n",
      "+-----------+-----------+-------------+\n",
      "| 28        | 28        | 0.129       |\n",
      "+-----------+-----------+-------------+\n",
      "| 29        | 29        | 0.296       |\n",
      "+-----------+-----------+-------------+\n",
      "| 30        | 30        | 0.349       |\n",
      "+-----------+-----------+-------------+\n",
      "| 31        | 31        | 0.263       |\n",
      "+-----------+-----------+-------------+\n",
      "| 32        | 34        | 0.294       |\n",
      "+-----------+-----------+-------------+\n",
      "| 33        | 33        | 0.267       |\n",
      "+-----------+-----------+-------------+\n",
      "| 34        | 34        | 0.244       |\n",
      "+-----------+-----------+-------------+\n",
      "| 35        | 35        | 0.331       |\n",
      "+-----------+-----------+-------------+\n",
      "| 36        | 21        | 0.315       |\n",
      "+-----------+-----------+-------------+\n",
      "| 37        | 37        | 0.240       |\n",
      "+-----------+-----------+-------------+\n",
      "| 38        | 38        | 0.203       |\n",
      "+-----------+-----------+-------------+\n",
      "| 39        | 36        | 0.296       |\n",
      "+-----------+-----------+-------------+\n",
      "| 40        | 40        | 0.187       |\n",
      "+-----------+-----------+-------------+\n",
      "| 41        | 41        | 0.393       |\n",
      "+-----------+-----------+-------------+\n",
      "| 42        | 18        | 0.236       |\n",
      "+-----------+-----------+-------------+\n",
      "| 43        | 43        | 0.213       |\n",
      "+-----------+-----------+-------------+\n",
      "| 44        | 13        | 0.455       |\n",
      "+-----------+-----------+-------------+\n",
      "| 45        | 45        | 0.290       |\n",
      "+-----------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "output_ids, match_scores = get_search_results(query_embeddings, index)\n",
    "print_result(clause_ids, output_ids, match_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d6470a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7346938775510204"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(clause_ids, output_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77842170",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## For ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94d1cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bf625b92e245b6976eca51ab7cc05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72dd0a53f504ac0acb071cbbbb782d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee923298b6e34e82b13d564a0b062509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175fb11fb4924ebda99aa0a5cc6f8662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PreTrainedTokenizerFast(name_or_path='albert-base-v2', vocab_size=30000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '<unk>', 'sep_token': '[SEP]', 'pad_token': '<pad>', 'cls_token': '[CLS]', 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False)}),\n",
       " AlbertModel(\n",
       "   (embeddings): AlbertEmbeddings(\n",
       "     (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "     (position_embeddings): Embedding(512, 128)\n",
       "     (token_type_embeddings): Embedding(2, 128)\n",
       "     (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0, inplace=False)\n",
       "   )\n",
       "   (encoder): AlbertTransformer(\n",
       "     (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "     (albert_layer_groups): ModuleList(\n",
       "       (0): AlbertLayerGroup(\n",
       "         (albert_layers): ModuleList(\n",
       "           (0): AlbertLayer(\n",
       "             (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (attention): AlbertAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (attention_dropout): Dropout(p=0, inplace=False)\n",
       "               (output_dropout): Dropout(p=0, inplace=False)\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             )\n",
       "             (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (pooler_activation): Tanh()\n",
       " ))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer, model = load_models(model_name='albert-base-v2')\n",
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec38feb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clause_embeddings = get_embeddings(clauses, tokenizer, model)\n",
    "clause_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd73df6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nmslib.FloatIndex method='hnsw' space='cosinesimil' at 0x55dd0b6c5b90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_and_store_index(clause_embeddings, name=os.path.join(indices_dir, 'albertv2'))\n",
    "index = load_index(name=os.path.join(indices_dir, 'albertv2'))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65efb75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = get_embeddings(queries, tokenizer, model)\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eea1806",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+\n",
      "| clause_id | output_id | match_score |\n",
      "+-----------+-----------+-------------+\n",
      "| 1         | 41        | 0.146       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 3         | 0.153       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 3         | 0.136       |\n",
      "+-----------+-----------+-------------+\n",
      "| 3         | 3         | 0.151       |\n",
      "+-----------+-----------+-------------+\n",
      "| 4         | 4         | 0.150       |\n",
      "+-----------+-----------+-------------+\n",
      "| 5         | 4         | 0.117       |\n",
      "+-----------+-----------+-------------+\n",
      "| 6         | 41        | 0.127       |\n",
      "+-----------+-----------+-------------+\n",
      "| 7         | 38        | 0.093       |\n",
      "+-----------+-----------+-------------+\n",
      "| 8         | 41        | 0.138       |\n",
      "+-----------+-----------+-------------+\n",
      "| 9         | 3         | 0.157       |\n",
      "+-----------+-----------+-------------+\n",
      "| 10        | 41        | 0.134       |\n",
      "+-----------+-----------+-------------+\n",
      "| 11        | 11        | 0.134       |\n",
      "+-----------+-----------+-------------+\n",
      "| 12        | 3         | 0.174       |\n",
      "+-----------+-----------+-------------+\n",
      "| 13        | 13        | 0.121       |\n",
      "+-----------+-----------+-------------+\n",
      "| 14        | 14        | 0.160       |\n",
      "+-----------+-----------+-------------+\n",
      "| 15        | 15        | 0.122       |\n",
      "+-----------+-----------+-------------+\n",
      "| 16        | 12        | 0.159       |\n",
      "+-----------+-----------+-------------+\n",
      "| 17        | 3         | 0.127       |\n",
      "+-----------+-----------+-------------+\n",
      "| 18        | 41        | 0.137       |\n",
      "+-----------+-----------+-------------+\n",
      "| 19        | 22        | 0.210       |\n",
      "+-----------+-----------+-------------+\n",
      "| 20        | 20        | 0.170       |\n",
      "+-----------+-----------+-------------+\n",
      "| 21        | 21        | 0.157       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.169       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.199       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.212       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 41        | 0.094       |\n",
      "+-----------+-----------+-------------+\n",
      "| 23        | 3         | 0.148       |\n",
      "+-----------+-----------+-------------+\n",
      "| 24        | 24        | 0.123       |\n",
      "+-----------+-----------+-------------+\n",
      "| 25        | 10        | 0.093       |\n",
      "+-----------+-----------+-------------+\n",
      "| 26        | 11        | 0.103       |\n",
      "+-----------+-----------+-------------+\n",
      "| 27        | 11        | 0.138       |\n",
      "+-----------+-----------+-------------+\n",
      "| 28        | 41        | 0.144       |\n",
      "+-----------+-----------+-------------+\n",
      "| 29        | 29        | 0.070       |\n",
      "+-----------+-----------+-------------+\n",
      "| 30        | 3         | 0.136       |\n",
      "+-----------+-----------+-------------+\n",
      "| 31        | 3         | 0.120       |\n",
      "+-----------+-----------+-------------+\n",
      "| 32        | 34        | 0.103       |\n",
      "+-----------+-----------+-------------+\n",
      "| 33        | 33        | 0.173       |\n",
      "+-----------+-----------+-------------+\n",
      "| 34        | 34        | 0.133       |\n",
      "+-----------+-----------+-------------+\n",
      "| 35        | 4         | 0.150       |\n",
      "+-----------+-----------+-------------+\n",
      "| 36        | 22        | 0.151       |\n",
      "+-----------+-----------+-------------+\n",
      "| 37        | 37        | 0.105       |\n",
      "+-----------+-----------+-------------+\n",
      "| 38        | 21        | 0.114       |\n",
      "+-----------+-----------+-------------+\n",
      "| 39        | 39        | 0.129       |\n",
      "+-----------+-----------+-------------+\n",
      "| 40        | 3         | 0.133       |\n",
      "+-----------+-----------+-------------+\n",
      "| 41        | 41        | 0.072       |\n",
      "+-----------+-----------+-------------+\n",
      "| 42        | 41        | 0.156       |\n",
      "+-----------+-----------+-------------+\n",
      "| 43        | 14        | 0.134       |\n",
      "+-----------+-----------+-------------+\n",
      "| 44        | 41        | 0.106       |\n",
      "+-----------+-----------+-------------+\n",
      "| 45        | 41        | 0.117       |\n",
      "+-----------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "output_ids, match_scores = get_search_results(query_embeddings, index)\n",
    "print_result(clause_ids, output_ids, match_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2db6a9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3673469387755102"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(clause_ids, output_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c892b23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## For universal encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe8b0a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 100.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 190.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 270.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 340.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 390.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 430.04MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 510.04MB\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/5, Total size: 577.10MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_hub import load\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "model = load( module_url )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "458b2a15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([45, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed(input):\n",
    "    return model( input )\n",
    "\n",
    "clause_embeddings = embed(clauses)\n",
    "clause_embeddings.shape\n",
    "# clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2914648e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nmslib.FloatIndex method='hnsw' space='cosinesimil' at 0x55dd35d0edf0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_and_store_index(clause_embeddings, name=os.path.join(indices_dir, 'UniversalSentenceEncoderLarge'))\n",
    "index = load_index(name=os.path.join(indices_dir, 'UniversalSentenceEncoderLarge'))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71b45c26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([49, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = embed(queries)\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47360ca2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+\n",
      "| clause_id | output_id | match_score |\n",
      "+-----------+-----------+-------------+\n",
      "| 1         | 33        | 0.727       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 2         | 0.518       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 2         | 0.656       |\n",
      "+-----------+-----------+-------------+\n",
      "| 3         | 26        | 0.626       |\n",
      "+-----------+-----------+-------------+\n",
      "| 4         | 4         | 0.345       |\n",
      "+-----------+-----------+-------------+\n",
      "| 5         | 5         | 0.662       |\n",
      "+-----------+-----------+-------------+\n",
      "| 6         | 6         | 0.621       |\n",
      "+-----------+-----------+-------------+\n",
      "| 7         | 7         | 0.609       |\n",
      "+-----------+-----------+-------------+\n",
      "| 8         | 8         | 0.545       |\n",
      "+-----------+-----------+-------------+\n",
      "| 9         | 9         | 0.786       |\n",
      "+-----------+-----------+-------------+\n",
      "| 10        | 10        | 0.488       |\n",
      "+-----------+-----------+-------------+\n",
      "| 11        | 11        | 0.342       |\n",
      "+-----------+-----------+-------------+\n",
      "| 12        | 12        | 0.526       |\n",
      "+-----------+-----------+-------------+\n",
      "| 13        | 13        | 0.548       |\n",
      "+-----------+-----------+-------------+\n",
      "| 14        | 14        | 0.608       |\n",
      "+-----------+-----------+-------------+\n",
      "| 15        | 15        | 0.303       |\n",
      "+-----------+-----------+-------------+\n",
      "| 16        | 16        | 0.572       |\n",
      "+-----------+-----------+-------------+\n",
      "| 17        | 16        | 0.544       |\n",
      "+-----------+-----------+-------------+\n",
      "| 18        | 42        | 0.611       |\n",
      "+-----------+-----------+-------------+\n",
      "| 19        | 19        | 0.500       |\n",
      "+-----------+-----------+-------------+\n",
      "| 20        | 20        | 0.585       |\n",
      "+-----------+-----------+-------------+\n",
      "| 21        | 21        | 0.562       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.421       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.463       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.545       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.465       |\n",
      "+-----------+-----------+-------------+\n",
      "| 23        | 23        | 0.589       |\n",
      "+-----------+-----------+-------------+\n",
      "| 24        | 24        | 0.440       |\n",
      "+-----------+-----------+-------------+\n",
      "| 25        | 7         | 0.575       |\n",
      "+-----------+-----------+-------------+\n",
      "| 26        | 26        | 0.447       |\n",
      "+-----------+-----------+-------------+\n",
      "| 27        | 27        | 0.515       |\n",
      "+-----------+-----------+-------------+\n",
      "| 28        | 28        | 0.284       |\n",
      "+-----------+-----------+-------------+\n",
      "| 29        | 29        | 0.392       |\n",
      "+-----------+-----------+-------------+\n",
      "| 30        | 30        | 0.600       |\n",
      "+-----------+-----------+-------------+\n",
      "| 31        | 31        | 0.585       |\n",
      "+-----------+-----------+-------------+\n",
      "| 32        | 34        | 0.397       |\n",
      "+-----------+-----------+-------------+\n",
      "| 33        | 33        | 0.507       |\n",
      "+-----------+-----------+-------------+\n",
      "| 34        | 34        | 0.528       |\n",
      "+-----------+-----------+-------------+\n",
      "| 35        | 12        | 0.546       |\n",
      "+-----------+-----------+-------------+\n",
      "| 36        | 36        | 0.489       |\n",
      "+-----------+-----------+-------------+\n",
      "| 37        | 37        | 0.450       |\n",
      "+-----------+-----------+-------------+\n",
      "| 38        | 21        | 0.403       |\n",
      "+-----------+-----------+-------------+\n",
      "| 39        | 39        | 0.474       |\n",
      "+-----------+-----------+-------------+\n",
      "| 40        | 40        | 0.730       |\n",
      "+-----------+-----------+-------------+\n",
      "| 41        | 41        | 0.447       |\n",
      "+-----------+-----------+-------------+\n",
      "| 42        | 42        | 0.559       |\n",
      "+-----------+-----------+-------------+\n",
      "| 43        | 43        | 0.561       |\n",
      "+-----------+-----------+-------------+\n",
      "| 44        | 44        | 0.723       |\n",
      "+-----------+-----------+-------------+\n",
      "| 45        | 45        | 0.497       |\n",
      "+-----------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "output_ids, match_scores = get_search_results(query_embeddings, index)\n",
    "print_result(clause_ids, output_ids, match_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e8bb545",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8367346938775511"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(clause_ids, output_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773e976",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## For BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "275fe9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495fef5f8c3c4d30bd5dd2c29dc3010f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6189016d0946689c12c424cdacf69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       " BertModel(\n",
       "   (embeddings): BertEmbeddings(\n",
       "     (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "     (position_embeddings): Embedding(512, 768)\n",
       "     (token_type_embeddings): Embedding(2, 768)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (encoder): BertEncoder(\n",
       "     (layer): ModuleList(\n",
       "       (0): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (2): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (3): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (4): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (5): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (6): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (7): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (8): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (9): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (10): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (11): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pooler): BertPooler(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (activation): Tanh()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer, model = load_models(model_name='bert-base-uncased')\n",
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5784a6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clause_embeddings = get_embeddings(clauses, tokenizer, model)\n",
    "clause_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1660cd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nmslib.FloatIndex method='hnsw' space='cosinesimil' at 0x561879205a70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_and_store_index(clause_embeddings, name=os.path.join(indices_dir, 'bert-base'))\n",
    "index = load_index(name=os.path.join(indices_dir, 'bert-base'))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a313ac0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = get_embeddings(queries, tokenizer, model)\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd469f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+\n",
      "| clause_id | output_id | match_score |\n",
      "+-----------+-----------+-------------+\n",
      "| 1         | 41        | 0.264       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 2         | 0.307       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 23        | 0.303       |\n",
      "+-----------+-----------+-------------+\n",
      "| 3         | 23        | 0.296       |\n",
      "+-----------+-----------+-------------+\n",
      "| 4         | 4         | 0.248       |\n",
      "+-----------+-----------+-------------+\n",
      "| 5         | 4         | 0.354       |\n",
      "+-----------+-----------+-------------+\n",
      "| 6         | 41        | 0.272       |\n",
      "+-----------+-----------+-------------+\n",
      "| 7         | 25        | 0.195       |\n",
      "+-----------+-----------+-------------+\n",
      "| 8         | 22        | 0.310       |\n",
      "+-----------+-----------+-------------+\n",
      "| 9         | 9         | 0.311       |\n",
      "+-----------+-----------+-------------+\n",
      "| 10        | 10        | 0.230       |\n",
      "+-----------+-----------+-------------+\n",
      "| 11        | 11        | 0.293       |\n",
      "+-----------+-----------+-------------+\n",
      "| 12        | 28        | 0.370       |\n",
      "+-----------+-----------+-------------+\n",
      "| 13        | 13        | 0.191       |\n",
      "+-----------+-----------+-------------+\n",
      "| 14        | 22        | 0.359       |\n",
      "+-----------+-----------+-------------+\n",
      "| 15        | 28        | 0.258       |\n",
      "+-----------+-----------+-------------+\n",
      "| 16        | 23        | 0.351       |\n",
      "+-----------+-----------+-------------+\n",
      "| 17        | 19        | 0.284       |\n",
      "+-----------+-----------+-------------+\n",
      "| 18        | 42        | 0.302       |\n",
      "+-----------+-----------+-------------+\n",
      "| 19        | 19        | 0.423       |\n",
      "+-----------+-----------+-------------+\n",
      "| 20        | 19        | 0.355       |\n",
      "+-----------+-----------+-------------+\n",
      "| 21        | 21        | 0.273       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.319       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.306       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.267       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 19        | 0.231       |\n",
      "+-----------+-----------+-------------+\n",
      "| 23        | 23        | 0.184       |\n",
      "+-----------+-----------+-------------+\n",
      "| 24        | 24        | 0.266       |\n",
      "+-----------+-----------+-------------+\n",
      "| 25        | 10        | 0.197       |\n",
      "+-----------+-----------+-------------+\n",
      "| 26        | 12        | 0.218       |\n",
      "+-----------+-----------+-------------+\n",
      "| 27        | 27        | 0.312       |\n",
      "+-----------+-----------+-------------+\n",
      "| 28        | 28        | 0.272       |\n",
      "+-----------+-----------+-------------+\n",
      "| 29        | 29        | 0.164       |\n",
      "+-----------+-----------+-------------+\n",
      "| 30        | 27        | 0.296       |\n",
      "+-----------+-----------+-------------+\n",
      "| 31        | 17        | 0.270       |\n",
      "+-----------+-----------+-------------+\n",
      "| 32        | 34        | 0.301       |\n",
      "+-----------+-----------+-------------+\n",
      "| 33        | 19        | 0.273       |\n",
      "+-----------+-----------+-------------+\n",
      "| 34        | 19        | 0.322       |\n",
      "+-----------+-----------+-------------+\n",
      "| 35        | 33        | 0.242       |\n",
      "+-----------+-----------+-------------+\n",
      "| 36        | 36        | 0.194       |\n",
      "+-----------+-----------+-------------+\n",
      "| 37        | 37        | 0.264       |\n",
      "+-----------+-----------+-------------+\n",
      "| 38        | 21        | 0.237       |\n",
      "+-----------+-----------+-------------+\n",
      "| 39        | 39        | 0.230       |\n",
      "+-----------+-----------+-------------+\n",
      "| 40        | 40        | 0.242       |\n",
      "+-----------+-----------+-------------+\n",
      "| 41        | 41        | 0.195       |\n",
      "+-----------+-----------+-------------+\n",
      "| 42        | 42        | 0.273       |\n",
      "+-----------+-----------+-------------+\n",
      "| 43        | 43        | 0.204       |\n",
      "+-----------+-----------+-------------+\n",
      "| 44        | 44        | 0.294       |\n",
      "+-----------+-----------+-------------+\n",
      "| 45        | 41        | 0.250       |\n",
      "+-----------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "output_ids, match_scores = get_search_results(query_embeddings, index)\n",
    "print_result(clause_ids, output_ids, match_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a27e94bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4897959183673469"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(clause_ids, output_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a466e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## For RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e0763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PreTrainedTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}),\n",
       " RobertaModel(\n",
       "   (embeddings): RobertaEmbeddings(\n",
       "     (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "     (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "     (token_type_embeddings): Embedding(1, 768)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (encoder): RobertaEncoder(\n",
       "     (layer): ModuleList(\n",
       "       (0): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (2): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (3): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (4): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (5): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (6): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (7): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (8): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (9): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (10): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (11): RobertaLayer(\n",
       "         (attention): RobertaAttention(\n",
       "           (self): RobertaSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): RobertaSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): RobertaIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         )\n",
       "         (output): RobertaOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pooler): RobertaPooler(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (activation): Tanh()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer, model = load_models(model_name='roberta-base')\n",
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a955f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clause_embeddings = get_embeddings(clauses, tokenizer, model)\n",
    "clause_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6104c255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nmslib.FloatIndex method='hnsw' space='cosinesimil' at 0x55b8acfa5e30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_and_store_index(clause_embeddings, name=os.path.join(indices_dir, 'roberta-base'))\n",
    "index = load_index(name=os.path.join(indices_dir, 'roberta-base'))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14cb3df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = get_embeddings(queries, tokenizer, model)\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfadc004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+\n",
      "| clause_id | output_id | match_score |\n",
      "+-----------+-----------+-------------+\n",
      "| 1         | 37        | 0.025       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 4         | 0.025       |\n",
      "+-----------+-----------+-------------+\n",
      "| 2         | 4         | 0.028       |\n",
      "+-----------+-----------+-------------+\n",
      "| 3         | 37        | 0.023       |\n",
      "+-----------+-----------+-------------+\n",
      "| 4         | 4         | 0.023       |\n",
      "+-----------+-----------+-------------+\n",
      "| 5         | 5         | 0.025       |\n",
      "+-----------+-----------+-------------+\n",
      "| 6         | 41        | 0.026       |\n",
      "+-----------+-----------+-------------+\n",
      "| 7         | 19        | 0.018       |\n",
      "+-----------+-----------+-------------+\n",
      "| 8         | 4         | 0.025       |\n",
      "+-----------+-----------+-------------+\n",
      "| 9         | 3         | 0.026       |\n",
      "+-----------+-----------+-------------+\n",
      "| 10        | 39        | 0.020       |\n",
      "+-----------+-----------+-------------+\n",
      "| 11        | 11        | 0.024       |\n",
      "+-----------+-----------+-------------+\n",
      "| 12        | 4         | 0.033       |\n",
      "+-----------+-----------+-------------+\n",
      "| 13        | 4         | 0.025       |\n",
      "+-----------+-----------+-------------+\n",
      "| 14        | 14        | 0.031       |\n",
      "+-----------+-----------+-------------+\n",
      "| 15        | 11        | 0.022       |\n",
      "+-----------+-----------+-------------+\n",
      "| 16        | 33        | 0.027       |\n",
      "+-----------+-----------+-------------+\n",
      "| 17        | 41        | 0.029       |\n",
      "+-----------+-----------+-------------+\n",
      "| 18        | 4         | 0.026       |\n",
      "+-----------+-----------+-------------+\n",
      "| 19        | 22        | 0.038       |\n",
      "+-----------+-----------+-------------+\n",
      "| 20        | 22        | 0.029       |\n",
      "+-----------+-----------+-------------+\n",
      "| 21        | 4         | 0.023       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.026       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.034       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 22        | 0.036       |\n",
      "+-----------+-----------+-------------+\n",
      "| 22        | 37        | 0.013       |\n",
      "+-----------+-----------+-------------+\n",
      "| 23        | 23        | 0.020       |\n",
      "+-----------+-----------+-------------+\n",
      "| 24        | 41        | 0.022       |\n",
      "+-----------+-----------+-------------+\n",
      "| 25        | 23        | 0.015       |\n",
      "+-----------+-----------+-------------+\n",
      "| 26        | 11        | 0.019       |\n",
      "+-----------+-----------+-------------+\n",
      "| 27        | 28        | 0.025       |\n",
      "+-----------+-----------+-------------+\n",
      "| 28        | 28        | 0.015       |\n",
      "+-----------+-----------+-------------+\n",
      "| 29        | 29        | 0.016       |\n",
      "+-----------+-----------+-------------+\n",
      "| 30        | 11        | 0.024       |\n",
      "+-----------+-----------+-------------+\n",
      "| 31        | 37        | 0.019       |\n",
      "+-----------+-----------+-------------+\n",
      "| 32        | 34        | 0.022       |\n",
      "+-----------+-----------+-------------+\n",
      "| 33        | 33        | 0.023       |\n",
      "+-----------+-----------+-------------+\n",
      "| 34        | 4         | 0.024       |\n",
      "+-----------+-----------+-------------+\n",
      "| 35        | 4         | 0.026       |\n",
      "+-----------+-----------+-------------+\n",
      "| 36        | 22        | 0.024       |\n",
      "+-----------+-----------+-------------+\n",
      "| 37        | 37        | 0.017       |\n",
      "+-----------+-----------+-------------+\n",
      "| 38        | 37        | 0.024       |\n",
      "+-----------+-----------+-------------+\n",
      "| 39        | 37        | 0.015       |\n",
      "+-----------+-----------+-------------+\n",
      "| 40        | 3         | 0.023       |\n",
      "+-----------+-----------+-------------+\n",
      "| 41        | 41        | 0.015       |\n",
      "+-----------+-----------+-------------+\n",
      "| 42        | 22        | 0.027       |\n",
      "+-----------+-----------+-------------+\n",
      "| 43        | 37        | 0.018       |\n",
      "+-----------+-----------+-------------+\n",
      "| 44        | 37        | 0.025       |\n",
      "+-----------+-----------+-------------+\n",
      "| 45        | 41        | 0.022       |\n",
      "+-----------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "output_ids, match_scores = get_search_results(query_embeddings, index)\n",
    "print_result(clause_ids, output_ids, match_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35029bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2653061224489796"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(clause_ids, output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee517f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
